import json
import re
from typing import List, Optional, Dict, Any, Tuple
from domain.entity.rag_memory import RAGMemory, MemoryType
from domain.interfaces.ai_client import AIClientInterface
from infrastructure.monitoring.logging import StructuredLogger


class RAGService:
    """Ð¡ÐµÑ€Ð²Ð¸Ñ Ð´Ð»Ñ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ñ Ð¸ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ð¿Ð°Ð¼ÑÑ‚ÑŒÑŽ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ"""

    def __init__(self, ai_client: AIClientInterface):
        self.ai_client = ai_client
        self.logger = StructuredLogger("rag_service")

    async def extract_memories_from_message(self, user_id: int, message: str) -> List[RAGMemory]:
        """Ð˜Ð·Ð²Ð»ÐµÑ‡ÑŒ Ð²Ð°Ð¶Ð½Ñ‹Ðµ Ñ„Ð°ÐºÑ‚Ñ‹ Ð˜Ð¡ÐšÐ›Ð®Ð§Ð˜Ð¢Ð•Ð›Ð¬ÐÐž Ð¸Ð· Ñ‚ÐµÐºÑƒÑ‰ÐµÐ³Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ"""

        # Ð£ÐŸÐ ÐžÐ©Ð•ÐÐÐ«Ð™ Ð˜ Ð‘ÐžÐ›Ð•Ð• Ð­Ð¤Ð¤Ð•ÐšÐ¢Ð˜Ð’ÐÐ«Ð™ ÐŸÐ ÐžÐœÐŸÐ¢
        system_prompt = """
        Ð¢Ñ‹ â€” Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚ Ð´Ð»Ñ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ñ Ð¿ÐµÑ€ÑÐ¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ñ… Ñ„Ð°ÐºÑ‚Ð¾Ð² Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ðµ. 
        ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð¸ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸Ñ†Ð¸Ñ€ÑƒÐ¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¿Ð¾ Ñ‚Ð¸Ð¿Ð°Ð¼:

        Ð¢Ð˜ÐŸÐ« Ð¤ÐÐšÐ¢ÐžÐ’ Ð˜ ÐŸÐ Ð˜ÐœÐ•Ð Ð«:
        1. personal_detail - Ð›Ð¸Ñ‡Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ (Ð¸Ð¼Ñ, Ð³Ð¾Ñ€Ð¾Ð´, Ñ€Ð°Ð±Ð¾Ñ‚Ð°)
           ÐŸÑ€Ð¸Ð¼ÐµÑ€: "ÐœÐµÐ½Ñ Ð·Ð¾Ð²ÑƒÑ‚ ÐÐ½Ð½Ð°" â†’ Ñ‚Ð¸Ð¿: personal_detail

        2. age - Ð’Ð¾Ð·Ñ€Ð°ÑÑ‚ Ð² Ð³Ð¾Ð´Ð°Ñ…
           ÐŸÑ€Ð¸Ð¼ÐµÑ€: "ÐœÐ½Ðµ 25 Ð»ÐµÑ‚" â†’ Ñ‚Ð¸Ð¿: age

        3. interest - Ð˜Ð½Ñ‚ÐµÑ€ÐµÑÑ‹ Ð¸ Ñ…Ð¾Ð±Ð±Ð¸
           ÐŸÑ€Ð¸Ð¼ÐµÑ€: "Ð›ÑŽÐ±Ð»ÑŽ Ñ‡Ð¸Ñ‚Ð°Ñ‚ÑŒ ÐºÐ½Ð¸Ð³Ð¸" â†’ Ñ‚Ð¸Ð¿: interest

        4. mood - Ð¢ÐµÐºÑƒÑ‰ÐµÐµ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ðµ
           ÐŸÑ€Ð¸Ð¼ÐµÑ€: "Ð¡ÐµÐ³Ð¾Ð´Ð½Ñ Ñ ÑÑ‡Ð°ÑÑ‚Ð»Ð¸Ð²" â†’ Ñ‚Ð¸Ð¿: mood

        5. personal_characteristic - Ð§ÐµÑ€Ñ‚Ñ‹ Ñ…Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð°
           ÐŸÑ€Ð¸Ð¼ÐµÑ€: "Ð¯ Ñ‚ÐµÑ€Ð¿ÐµÐ»Ð¸Ð²Ñ‹Ð¹ Ñ‡ÐµÐ»Ð¾Ð²ÐµÐº" â†’ Ñ‚Ð¸Ð¿: personal_characteristic

        6. habit - ÐŸÑ€Ð¸Ð²Ñ‹Ñ‡ÐºÐ¸ Ð¸ Ñ€ÑƒÑ‚Ð¸Ð½Ñ‹  
           ÐŸÑ€Ð¸Ð¼ÐµÑ€: "ÐšÐ°Ð¶Ð´Ð¾Ðµ ÑƒÑ‚Ñ€Ð¾ Ð±ÐµÐ³Ð°ÑŽ" â†’ Ñ‚Ð¸Ð¿: habit

        7. goal - Ð¦ÐµÐ»Ð¸ Ð¸ Ð¼ÐµÑ‡Ñ‚Ñ‹
           ÐŸÑ€Ð¸Ð¼ÐµÑ€: "Ð¥Ð¾Ñ‡Ñƒ Ð²Ñ‹ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð°Ð½Ð³Ð»Ð¸Ð¹ÑÐºÐ¸Ð¹" â†’ Ñ‚Ð¸Ð¿: goal

        8. event - Ð’Ð°Ð¶Ð½Ñ‹Ðµ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ
           ÐŸÑ€Ð¸Ð¼ÐµÑ€: "Ð’Ñ‡ÐµÑ€Ð° Ð·Ð°Ñ‰Ð¸Ñ‚Ð¸Ð» Ð´Ð¸Ð¿Ð»Ð¾Ð¼" â†’ Ñ‚Ð¸Ð¿: event

        9. preference - ÐŸÑ€ÐµÐ´Ð¿Ð¾Ñ‡Ñ‚ÐµÐ½Ð¸Ñ Ð¸ Ð²ÐºÑƒÑÑ‹
           ÐŸÑ€Ð¸Ð¼ÐµÑ€: "ÐŸÑ€ÐµÐ´Ð¿Ð¾Ñ‡Ð¸Ñ‚Ð°ÑŽ Ñ‡Ð°Ð¹ ÐºÐ¾Ñ„Ðµ" â†’ Ñ‚Ð¸Ð¿: preference

        Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚ Ð¾Ñ‚Ð²ÐµÑ‚Ð° - JSON:
        {
            "memories": [
                {
                    "type": "Ð¢Ð˜ÐŸ_Ð˜Ð—_Ð¡ÐŸÐ˜Ð¡ÐšÐ_Ð’Ð«Ð¨Ð•",
                    "content": "ÐšÑ€Ð°Ñ‚ÐºÐ°Ñ Ñ„Ð¾Ñ€Ð¼ÑƒÐ»Ð¸Ñ€Ð¾Ð²ÐºÐ°",
                    "importance": 0.7,
                    "metadata": {
                        "Ð²Ð¾Ð·Ñ€Ð°ÑÑ‚": 25,
                        "Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ðµ": "Ñ€Ð°Ð´Ð¾ÑÑ‚Ð½Ð¾Ðµ",
                        "Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÑ‹": ["Ñ‡Ñ‚ÐµÐ½Ð¸Ðµ", "ÑÐ¿Ð¾Ñ€Ñ‚"]
                    }
                }
            ]
        }

        Ð˜Ð·Ð²Ð»ÐµÐºÐ°Ð¹ Ð¢ÐžÐ›Ð¬ÐšÐž ÐµÑÐ»Ð¸ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ ÑÐ²Ð½Ð¾ ÑƒÐºÐ°Ð·Ð°Ð½Ð° Ð² ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¸.
        """

        user_prompt = f"""
    Ð¡Ð¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ: "{message}"

    Ð˜Ð·Ð²Ð»ÐµÐºÐ¸ Ð¢ÐžÐ›Ð¬ÐšÐž Ð½Ð¾Ð²Ñ‹Ðµ Ð¿ÐµÑ€ÑÐ¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ñ„Ð°ÐºÑ‚Ñ‹ Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ðµ Ð¸Ð· ÑÑ‚Ð¾Ð³Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ.
    """

        try:
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]

            response = await self.ai_client.generate_response(
                messages,
                max_tokens=500,  # Ð£Ð¼ÐµÐ½ÑŒÑˆÐ°ÐµÐ¼, Ñ‚.Ðº. Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¾Ð´Ð½Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ
                temperature=0.1
            )

            memories_data = self._parse_llm_response(response)

            memories = []
            for mem_data in memories_data.get('memories', []):
                content = mem_data['content'].lower()

                # Ð¤Ð¸Ð»ÑŒÑ‚Ñ€ÑƒÐµÐ¼ Ñ„Ð°ÐºÑ‚Ñ‹, ÑÐ²ÑÐ·Ð°Ð½Ð½Ñ‹Ðµ Ñ Ð±Ð¾Ñ‚Ð¾Ð¼
                bot_keywords = ['Ð°Ð¹Ð½Ð°', 'Ð±Ð¾Ñ‚', 'Ñ‚Ñ‹ ', 'Ñ‚ÐµÐ±Ðµ', 'Ñ‚Ð²Ð¾Ð¹', 'Ñ‚Ð²Ð¾Ñ', 'Ñ‚Ð²Ð¾Ñ‘', 'Ñƒ Ñ‚ÐµÐ±Ñ', 'Ñ‚ÐµÐ±Ñ']
                if any(keyword in content for keyword in bot_keywords):
                    self.logger.debug(f"Filtered bot-related memory: {mem_data['content']}")
                    continue

                memory = RAGMemory(
                    user_id=user_id,
                    memory_type=MemoryType(mem_data['type']),
                    content=mem_data['content'],
                    source_message=message,
                    importance_score=mem_data['importance']
                )
                memories.append(memory)

            self.logger.info(
                f"Extracted {len(memories)} memories from current message",
                extra={'user_id': user_id, 'message_length': len(message), 'memories_count': len(memories)}
            )

            return memories

        except Exception as e:
            self.logger.error(f"Error extracting memories: {e}")
            return []

    async def generate_embeddings(self, memories: List[RAGMemory]) -> List[RAGMemory]:
        try:
            for memory in memories:
                if memory.embedding is None:
                    # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð¼ÐµÑ‚Ð¾Ð´ get_embedding Ð¸Ð· ai_client
                    embedding = await self.ai_client.get_embedding(memory.content)
                    memory.embedding = embedding
            return memories
        except Exception as e:
            self.logger.error(f'Error generating embeddings: {e}')
            return memories

    def _parse_llm_response(self, response: str) -> Dict[str, Any]:
        """ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ JSON Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¾Ñ‚ LLM"""
        try:
            # ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¾Ñ‚ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ñ‹Ñ… markdown Ð±Ð»Ð¾ÐºÐ¾Ð²
            cleaned_response = re.sub(r'```json\s*|\s*```', '', response).strip()
            return json.loads(cleaned_response)
        except json.JSONDecodeError as e:
            self.logger.error(f"Failed to parse LLM response: {response}")
            return {"memories": []}

    def prepare_memories_for_context(self, memories: List[RAGMemory], max_tokens: int = 500) -> str:
        """ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð²Ð¾ÑÐ¿Ð¾Ð¼Ð¸Ð½Ð°Ð½Ð¸Ð¹ Ð´Ð»Ñ Ð²ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ Ð² ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð°"""
        if not memories:
            return ""

        context_parts = ["ðŸ’« Ð¯ Ð¿Ð¾Ð¼Ð½ÑŽ Ð¾ Ñ‚ÐµÐ±Ðµ:"]
        token_count = len("ðŸ’« Ð¯ Ð¿Ð¾Ð¼Ð½ÑŽ Ð¾ Ñ‚ÐµÐ±Ðµ:")

        for memory in sorted(memories, key=lambda x: x.importance_score, reverse=True):
            memory_text = f"â€¢ {memory.content}"
            memory_tokens = len(memory_text)

            if token_count + memory_tokens > max_tokens:
                break

            context_parts.append(memory_text)
            token_count += memory_tokens

        return "\n".join(context_parts)